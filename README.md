# Scalable RAG LLM Chatbot System

A Retrieval-Augmented Generation (RAG) chatbot that allows users to upload documents and ask questions, receiving contextually accurate answers powered by a quantized Mistral-7B LLM.

---

![Architecture](architecture.jpg)

## ğŸ“– Table of Contents

- [Project Overview](#project-overview)
- [Architecture](#architecture)
- [Tech Stack](#tech-stack)
- [Prerequisites](#prerequisites)
- [Installation & Setup](#installation--setup)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Scripts & Workers](#scripts--workers)
- [API Endpoints](#api-endpoints)
- [Configuration](#configuration)
- [Extending the Project](#extending-the-project)
- [Contributing](#contributing)
- [License](#license)
- [Contact](#contact)

---

## ğŸ“ Project Overview

This project implements a **Retrieval-Augmented Generation (RAG)** system to power a document-aware chatbot. Users can upload PDF documents to a local MinIO bucket, ask questions via a FastAPI endpoint, and receive answers generated by the quantized Mistral-7B LLM using retrieved document context.

Key features:
- Document ingestion and chunking
- Semantic embedding storage and retrieval
- Async task handling with RabbitMQ queues
- FastAPI-based question submission and polling
- Answer caching in Redis and DuckDB

---

## ğŸ—ï¸ Architecture

```plaintext
User Upload â†’ MinIO â†’ MinIO Event Queue (RabbitMQ)
  â†³ minio_event_worker â†’ Document Chunk Queue
    â†³ embedding_worker â†’ DuckDB (embeddings)

User Query â†’ FastAPI â†’ Query Queue
  â†³ embedding_worker â†’ Query Embedding Queue
    â†³ llm_worker â†’ Similarity Search (DuckDB)
       â†³ Mistral-7B â†’ Answer â†’ DuckDB & Redis

Client polls FastAPI with task_id â†’ Returns answer
```
---

## ğŸ’» Tech Stack

| Component      | Technology                   |
| -------------- | ---------------------------- |
| API            | FastAPI                      |
| Object Storage | MinIO                        |
| Queueing       | RabbitMQ                     |
| Embedding DB   | DuckDB                       |
| Cache          | Redis                        |
| Embeddings     | Sentence Transformer         |
| LLM            | Quantized Mistral-7B         |

---

## ğŸ”§ Prerequisites

- [Python 3.10+](https://www.python.org/downloads/)
- [Docker (optional)](https://www.docker.com/)
- Bash shell (Linux/macOS) or WSL on Windows
- Git

---

## ğŸš€ Installation & Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/scalable-rag-llm-chatbot.git
   cd scalable-rag-llm-chatbot
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure credentials**
   Update `app/config/minio_config.json`, `rabbitmq_config.json`, and `redis_config.json` with your endpoints and credentials.

4. **Start services & workers**
   ```bash
   cd script
   bash startup_script.sh
   ```

5. **Launch FastAPI**
   ```bash
   cd ../app
   python app.py
   ```

---

## âš™ï¸ Usage

1. **Upload a document**
   - Use the web UI of minio server.

2. **Submit a question**
   - `POST /ask` with JSON:
     ```json
     { "question": "What is RAG?" }
     ```
   - Response:
     ```json
     { "task_id": "abc123" }
     ```

3. **Retrieve the answer**
   - `GET /result/{task_id}`
   - Response:
     ```json
     { "task_id": "abc123", "answer": "Retrieval-Augmented Generation (RAG) ..." }
     ```

---

## ğŸ—‚ï¸ Project Structure

```plaintext
project_root/
â”œâ”€â”€ script/                  # Service startup scripts
â”‚   â”œâ”€â”€ start_minio.sh
â”‚   â”œâ”€â”€ start_rabbitmq.sh
â”‚   â”œâ”€â”€ start_redis.sh
â”‚   â”œâ”€â”€ start_workers.sh
â”‚   â”œâ”€â”€ start_scripts.sh
â”‚   â””â”€â”€ startup_script.sh
â”œâ”€â”€ app/                     # FastAPI app and modules
â”‚   â”œâ”€â”€ app.py               # REST API endpoints
â”‚   â”œâ”€â”€ logs/                # Application and worker logs
â”‚   â”œâ”€â”€ config/              # MinIO, RabbitMQ, Redis configs
â”‚   â”œâ”€â”€ embeddings/          # DuckDB database files
â”‚   â”œâ”€â”€ models/              # SentenceTransformer & Mistral-7B
â”‚   â”œâ”€â”€ services/            # Initialization scripts
â”‚   â”œâ”€â”€ utilities/           # Client and DB utilities
â”‚   â””â”€â”€ worker/              # Worker scripts (minio, embedding, llm)
â””â”€â”€ requirements.txt
```

---

## ğŸ› ï¸ Scripts & Workers

| Script / Worker                | Description                                                    |
| ------------------------------ | -------------------------------------------------------------- |
| `start_minio.sh`              | Starts MinIO, creates bucket, sets up event notification       |
| `start_rabbitmq.sh`           | Starts RabbitMQ, declares queues                               |
| `start_redis.sh`              | Starts Redis, syncs cache from DuckDB                          |   
| `start_scripts.sh`            | Starts start_minio.sh, start_rabbitmq.sh and start_redis.sh    |
| `start_workers.sh`            | Starts minio_event_worker.py, embedding_worker.py and llm_worker.py |
| `startup_script.sh`           | Starts all script(single script to run whole necessary script of project)                          |
| `minio_event_worker.py`       | Listens for MinIO uploads â†’ chunks and enqueues documents      |
| `embedding_worker.py`         | Embeds document chunks & queries â†’ stores embeddings/queues    |
| `llm_worker.py`               | Performs similarity search, prompts LLM, stores answers        |

---

## ğŸ”Œ API Endpoints

| Endpoint                | Method | Request Body                         | Description                           |
| ----------------------- | ------ | ------------------------------------ | ------------------------------------- |
| `/ask`                  | POST   | `{ "question": "..." }`         | Submit a question, returns `task_id` |
| `/result/{task_id}`     | GET    | â€”                                    | Retrieve answer by `task_id`         |
| `/health`   | GET |   â€”   | Return status of rabbitmq, database and redis servers               |

---

## âš™ï¸ Configuration

Configuration files live in `app/config/`:

- `minio_config.json`  â€“ MinIO endpoint, access key, secret key
- `rabbitmq_config.json` â€“ RabbitMQ host, port, credentials
- `redis_config.json`    â€“ Redis host, port, credentials

---

## ğŸŒ± Extending the Project

- **Vector DB**: Swap DuckDB with Faiss, Qdrant,Â or ChromaDB for larger corpora.
- **Streaming**: Add WebSockets/SSE for real-time answer streaming.
- **Deployment**: Containerize with Docker and orchestrate with Kubernetes.
- **Security**: Implement authentication/authorization for document access.
- **Custom Models**: Fine-tune embeddings or LLMs on domain-specific corpora.

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a new branch (`git checkout -b feature/YourFeature`)
3. Commit your changes (`git commit -m 'Add YourFeature'`)
4. Push to the branch (`git push origin feature/YourFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License. See `LICENSE` for details.

---

